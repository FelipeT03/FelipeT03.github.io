<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Resultados del Modelo BiLSTM NER</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2 {
            color: #2c3e50;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin-bottom: 20px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <h1>Resultados del Modelo BiLSTM NER</h1>
    
    <h2>Conjunto de datos: CoNLL-2002 (Espa√±ol)</h2>
    <p>
        Los modelos fueron entrenados y evaluados utilizando el conjunto de datos CoNLL-2002 para espa√±ol. Este conjunto de datos est√° espec√≠ficamente dise√±ado para tareas de Reconocimiento de Entidades Nombradas (NER) y contiene texto anotado con varios tipos de entidades, incluyendo nombres de personas, en los cuales se enfoca este proyecto.
    </p>
    <p>        
        El set de datos se compone de frases en espa√±ol, donde cada palabra est√° etiquetada como un tipo de entidad (por ejemplo, "O" para palabras que no son entidades, "B-PER" para el inicio de un nombre de persona, y "I-PER" para palabras adicionales en un nombre de persona). El objetivo del modelo es predecir si una palabra es un nombre de persona o no. En este caso se utilizar√°n las entidades "B-PER" e "I-PER" como datos personales.
    </p>
    
    <!-- Agregar la secci√≥n dentro de un cuadro y formatear con una lista -->
    <div style="border: 2px solid #000; padding: 10px; margin: 20px 0; background-color: #f8f8f8;">
        <strong>El conjunto de datos se divide en:</strong>
        <ul>
            <li>Entrenamiento: 8324 frases</li>
            <li>Validaci√≥n: 1916 frases</li>
            <li>Prueba: 1518 frases</li>
        </ul>
    </div>
    

    <h2>¬øQu√© es un Modelo BiLSTM?</h2>
    <p>
        Un modelo BiLSTM (Memoria a Corto-Largo Plazo Bidireccional) es un tipo de red neuronal recurrente que procesa secuencias de entrada en ambas direcciones, hacia adelante y hacia atr√°s. Este enfoque bidireccional permite al modelo capturar el contexto tanto de elementos pasados como futuros en una secuencia, haci√©ndolo particularmente efectivo para tareas como el Reconocimiento de Entidades Nombradas.
    </p>

    <h2>¬øPor qu√© BiLSTM?</h2>
    <p>
        Los datos personales se pueden encontrar en cualquier secci√≥n de una oraci√≥n, inluyendo el inicio de la misma. La arquitectura BiLSTM es capaz de capturar el contexto necesario para identificar estos elementos de datos personales en diferentes posiciones dentro de una frase. Adem√°s, la capacidad de procesar secuencias en ambas direcciones ayuda al modelo a comprender mejor el contexto y las relaciones entre las palabras en una oraci√≥n.
    </p>

    <h2>Arquitectura del Modelo BiLSTM</h2>
    <img src="https://www.researchgate.net/profile/Latifa-Nabila-Harfiya/publication/344751031/figure/fig2/AS:948365760155651@1603119425682/The-unfolded-architecture-of-Bidirectional-LSTM-BiLSTM-with-three-consecutive-steps.png" 
         alt="Arquitectura del Modelo BiLSTM" 
         style="width: 100%; max-width: 800px; height: auto; display: block; margin: 20px 0;">


    <h2>Modelo</h2>
    <p>
        <strong>Tokenizer:</strong><br>
        Se utiliza un tokenizer personalizado dise√±ado para dividir el texto en palabras individuales y asignar etiquetas seg√∫n las entidades detectadas. La tokenizaci√≥n se realiza simplemente dividiendo la frase en palabras utilizando split(), lo que separa las palabras por espacios.
    
        <br><br>
    
        <strong>Embeddings:</strong><br>
        Los embeddings son vectores de representaci√≥n num√©rica que capturan las caracter√≠sticas sem√°nticas de las palabras. En este proyecto, los embeddings se entrenan desde cero, adapt√°ndose espec√≠ficamente al conjunto de datos de nombres y entidades en espa√±ol. Esto permite capturar de manera m√°s precisa las relaciones contextuales relevantes para la identificaci√≥n de datos personales. El modelo usa √≠ndices de una funci√≥n hash como entrada para una capa de nn.Embedding dentro del modelo a ser entrenada.
    
        <br><br>
    
        <strong>Entrenamiento desde cero:</strong><br>
        El modelo y los embeddings se entrenan completamente desde cero, permitiendo que el sistema aprenda directamente de los datos etiquetados sin depender de modelos preentrenados. Esto se realiza con el fin de identificar si el modelo puede aprender de forma efectiva enfoc√°ndose m√°s en el contexto de la oraci√≥n que en las palabras individuales o incluso solo memorizar nombres personales.
    
        <br><br>
    
        <strong>Early Stopping:</strong><br>
        Se utiliza early stopping para prevenir el sobreajuste del modelo. El entrenamiento se detendr√° autom√°ticamente si no se observa una mejora en la p√©rdida de validaci√≥n (validation loss) en 0.01 durante 3 √©pocas consecutivas. 
    
        <br><br>
    
        <strong>M√©tricas principales:</strong><br>
        Las m√©tricas evaluadas incluyen:
        <ul>
            <li><strong>Accuracy:</strong> La proporci√≥n de predicciones correctas sobre el total de predicciones.</li>
            <li><strong>Precision:</strong> La capacidad del modelo para evitar falsos positivos al identificar nombres de personas.</li>
            <li><strong>Recall:</strong> Mide la capacidad del modelo para identificar correctamente todos los nombres de personas presentes en el texto.</li>
            <li><strong>F1-Score:</strong> Una m√©trica combinada que balancea la precisi√≥n y el recall, proporcionando una medida robusta del rendimiento global del modelo.</li>
        </ul>
    </p>
         

    <h2>Opci√≥n 1: Modelo BiLSTM a nivel de token</h2>
    <p>
        Se realizan dos variantes del modelo. En el primer enfoque, el modelo predice si cada token individual en una frase es un elemento de datos personales (espec√≠ficamente, un nombre de persona).
    </p>
    <h3>Beneficios de la predicci√≥n a nivel de token:</h3>
    <ul>
        <li>Identificaci√≥n detallada: Puede se√±alar exactamente qu√© palabras en una frase son datos personales.</li>
        <li>Consciente del contexto: La arquitectura BiLSTM permite al modelo considerar las palabras circundantes al hacer predicciones, mejorando la precisi√≥n.</li>
        <li>Flexible: Puede manejar frases de diferentes longitudes e identificar m√∫ltiples elementos de datos personales en una sola frase.</li>
    </ul>
    <h3>Resultados:</h3>
    <table>
        <tr>
            <th>M√©trica</th>
            <th>Valor</th>
        </tr>
        <tr>
            <td>Accuracy</td>
            <td>0.995</td>
        </tr>
        <tr>
            <td>Precision</td>
            <td>0.838</td>
        </tr>
        <tr>
            <td>Recall</td>
            <td>0.693</td>
        </tr>
        <tr>
            <td>F1 Score</td>
            <td>0.759</td>
        </tr>
    </table>
    Es importante notar que el valor elevado de Accuracy se debe a que la mayor√≠a de los tokens no son datos personales, lo que puede llevar a un desbalance en la m√©trica. Por otro lado, el F1 Score proporciona una medida m√°s equilibrada del rendimiento del modelo.
    <h2>Opci√≥n 2: Modelo BiLSTM a nivel de frase</h2>
    <p>
        Este enfoque predice si una frase en su totalidad contiene alg√∫n dato personal (nombres de personas), sin especificar qu√© tokens son los datos personales. Ya que en este caso no se especifica directamente si un token es un nombre de persona, sino si la frase en su totalidad contiene un nombre de persona, se busca que el modelo se enfoque m√°s en el contexto de la oraci√≥n que en el primer modelo.
    </p>
    <h3>Resultados:</h3>
    <table>
        <tr>
            <th>M√©trica</th>
            <th>Valor</th>
        </tr>
        <tr>
            <td>Accuracy</td>
            <td>0.840</td>
        </tr>
        <tr>
            <td>Precision</td>
            <td>0.736</td>
        </tr>
        <tr>
            <td>Recall</td>
            <td>0.780</td>
        </tr>
        <tr>
            <td>F1 Score</td>
            <td>0.758</td>
        </tr>
    </table>

    <h2>Conclusi√≥n</h2>
    <p>
        Ambos modelos muestran un rendimiento aceptable en la identificaci√≥n de datos personales, tomando en cuenta que no se aprovecha embeddings contextuales ni preentrenados y no usa un tokenizer sofisticado que maneje subtokens o representaciones m√°s avanzadas. Sin embargo, muestra que es capaz de identificar datos personales en funci√≥n del contexto m√°s que de las palabras individuales. Esto llega a ser relavante para casos de personas con nombres poco comunes.
    </p>
    <h2>Trabajo futuro</h2>
    <p>
        Para futuras iteraciones, se podr√≠a explorar el uso de embeddings preentrenados, como BERT o Word2Vec, para capturar mejor las relaciones sem√°nticas y contextuales entre las palabras. Adem√°s, se podr√≠a mejorar el tokenizer para manejar subtokens y representaciones m√°s detalladas de las palabras, lo que podr√≠a mejorar la precisi√≥n en la identificaci√≥n de datos personales. Esto se puede realizar tomando en cuenta que este modelo muestra que no solo se enfoca en las palabras individuales sino tambi√©n se apoya en el contexto de la oraci√≥n.
    </p>
    <h2>Ejemplos</h2>
    <p>
        A continuaci√≥n, se presentan algunos ejemplos de frases y las predicciones del modelo BiLSTM a nivel de token y a nivel de frase:
    </p>
    <style>
        .correct {
          background-color: rgba(0, 255, 0, 0.3); /* Verde semitransparente */
        }
        .incorrect {
          background-color: rgba(255, 0, 0, 0.3); /* Rojo semitransparente */
        }
      </style>
      
      <table class="dataframe table table-bordered">
        <thead>
          <tr style="text-align: right;">
            <th>Frase</th>
            <th>Opci√≥n 1 (Detecta)</th>
            <th>Opci√≥n 2 (Detecta)</th>
            <th>Contiene Nombre de Persona</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Anastasio del Villar estaba revisando los documentos en la oficina central.</td>
            <td class="incorrect">No</td>
            <td class="incorrect">No</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Maristela P√©rez caminaba por el parque durante la tarde soleada.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Olaf Monteverde nunca hab√≠a visto un paisaje tan hermoso en las monta√±as.</td>
            <td class="incorrect">No</td>
            <td class="incorrect">No</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Caetana Sald√≠var particip√≥ en la conferencia sobre energ√≠as renovables.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Zuleika Quintanilla gan√≥ el concurso de poes√≠a juvenil con su obra.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Isidro Yupanqui resolvi√≥ el problema matem√°tico m√°s complejo del examen.</td>
            <td class="incorrect">No</td>
            <td class="incorrect">No</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Milenka Guadalupe organiz√≥ un evento ben√©fico en su comunidad.</td>
            <td class="incorrect">No</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Leocadio Bustamante tiene un inter√©s especial en la historia precolombina.</td>
            <td class="correct">S√≠</td>
            <td class="incorrect">No</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Nicomedes Ar√°oz present√≥ un nuevo proyecto innovador en la feria de ciencias.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Edelmira Balc√°zar siempre so√±√≥ con tener una librer√≠a en el centro de la ciudad.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>El sol se escond√≠a lentamente detr√°s de las colinas, pintando el cielo de naranja y rosa.</td>
            <td class="correct">No</td>
            <td class="correct">No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Las plantas crec√≠an frondosamente despu√©s de la temporada de lluvias.</td>
            <td class="correct">No</td>
            <td class="correct">No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>El caf√© reci√©n hecho llen√≥ la cocina con un aroma agradable y reconfortante.</td>
            <td class="correct">No</td>
            <td class="incorrect">S√≠</td>
            <td>No</td>
          </tr>
          <tr>
            <td>El libro en la estanter√≠a era uno de los m√°s antiguos de la colecci√≥n.</td>
            <td class="correct">No</td>
            <td class="correct">No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>La m√°quina expendedora se descompuso justo cuando m√°s la necesitaban.</td>
            <td class="correct">No</td>
            <td class="correct">No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>El tren sali√≥ a tiempo, cruzando los campos verdes en su trayecto.</td>
            <td class="correct">No</td>
            <td class="incorrect">S√≠</td>
            <td>No</td>
          </tr>
          <tr>
            <td>El equipo trabaj√≥ arduamente para completar el proyecto antes del plazo.</td>
            <td class="correct">No</td>
            <td class="correct">No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Las olas romp√≠an suavemente contra la orilla, creando un sonido relajante.</td>
            <td class="correct">No</td>
            <td class="incorrect">S√≠</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Las luces de la ciudad brillaban intensamente durante la noche.</td>
            <td class="correct">No</td>
            <td class="correct">No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>La receta secreta de la abuela siempre hab√≠a sido el coraz√≥n de las reuniones familiares.</td>
            <td class="correct">No</td>
            <td class="correct">No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Mientras Juan P√©rez preparaba el desayuno, su tel√©fono comenz√≥ a sonar.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>La reuni√≥n fue organizada por Mar√≠a Gonz√°lez y su equipo de trabajo.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Luis Ram√≠rez lleg√≥ temprano al trabajo para revisar los informes pendientes.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Durante la presentaci√≥n, Ana L√≥pez explic√≥ detalladamente el proceso.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Carlos S√°nchez estaba convencido de que la soluci√≥n era la correcta.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Al final del d√≠a, Sof√≠a Torres recogi√≥ los documentos y los guard√≥ en la oficina.</td>
            <td class="incorrect">No</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>La idea fue sugerida originalmente por Jos√© Rodr√≠guez, aunque nadie lo recordaba.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Gabriela Fern√°ndez siempre llevaba una libreta para tomar notas importantes.</td>
            <td class="correct">S√≠</td>
            <td class="incorrect">No</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Despu√©s de la conferencia, Miguel Mart√≠nez se acerc√≥ a los ponentes para hacer preguntas.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
          <tr>
            <td>Laura Morales decidi√≥ que era momento de cambiar de carrera y seguir su pasi√≥n.</td>
            <td class="correct">S√≠</td>
            <td class="correct">S√≠</td>
            <td>S√≠</td>
          </tr>
       
      
        </tbody>
      </table>
      
      <h2>C√≥digo</h2>
      <p>
          El c√≥digo del proyecto est√° disponible en GitHub. Te invito a explorar el repositorio, revisar el notebook y trabajar con los datos para experimentar y mejorar el modelo de detecci√≥n de datos personales. Puedes ver el c√≥digo completo, ejecutar los experimentos y contribuir al proyecto.
      </p>
      <p>
          <a href="https://github.com/FelipeT03/NLP_PersonalInfoDetector/blob/main/NLP_project.ipynb" target="_blank" style="color: #007acc; text-decoration: none; font-weight: bold;">
              üåê Visita el repositorio en GitHub: NLP_PersonalInfoDetector
          </a>
      </p>
      <p>
          Si√©ntete libre de clonar el repositorio, realizar cambios y sugerir mejoras.
      </p>
      
</body>
</html>
